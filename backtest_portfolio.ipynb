{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import duckdb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import mplcursors  \n",
    "from pandas import Timestamp\n",
    "\n",
    "from factor_tools import create_extended_analysis_data\n",
    "from backtest_tools import (\n",
    "    CommissionModel, \n",
    "    FixedSlippageModel,\n",
    "    BrokersModel,\n",
    "    Trading,\n",
    "    Backtest,\n",
    "    load_distribution_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Strategy base class and implementations\n",
    "class PortfolioStrategy:\n",
    "    \"\"\"Base class for portfolio generation strategies\"\"\"\n",
    "    \n",
    "    def generate_portfolio_targets(self, data_df, min_price=2.0, market_cap_percentile=0.5, stock_num=10, logger=print):\n",
    "        \"\"\"\n",
    "        Generate target portfolio based on strategy logic\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        data_df : DataFrame\n",
    "            Daily stock data including factors\n",
    "        min_price : float\n",
    "            Minimum price threshold for stocks\n",
    "        market_cap_percentile : float\n",
    "            Market cap percentile threshold (0-1)\n",
    "        stock_num : int\n",
    "            Number of stocks to select\n",
    "        logger : function\n",
    "            Logging function\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        dict : {symbol: target_weight}\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Subclasses must implement generate_portfolio_targets\")\n",
    "\n",
    "\n",
    "class MultiFactorStrategy(PortfolioStrategy):\n",
    "    \"\"\"Strategy with simplified ranking logic using direct rank columns\"\"\"\n",
    "    \n",
    "    def __init__(self, industry_limit=2, store_intermediate=True):\n",
    "        \"\"\"\n",
    "        Initialize strategy\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        industry_limit : int\n",
    "            Maximum number of stocks per industry\n",
    "        \"\"\"\n",
    "        self.industry_limit = industry_limit\n",
    "        self.store_intermediate = store_intermediate\n",
    "        self.intermediate_dfs = {}  # Dictionary to store DataFrames at different stages\n",
    "\n",
    "    def generate_portfolio_targets(self, date, data_df, min_price=2.0, market_cap_percentile=0.5, stock_num=50, logger=print):\n",
    "        \"\"\"Generate portfolio targets using simplified approach\"\"\"\n",
    "    \n",
    "        # Reset intermediate storage for this run\n",
    "        if self.store_intermediate:\n",
    "            self.intermediate_dfs = {}\n",
    "\n",
    "        # Validate data\n",
    "        if data_df is None or len(data_df) == 0:\n",
    "            logger(\"Error: Empty dataframe passed to generate_portfolio_targets\")\n",
    "            return {}\n",
    "\n",
    "        # Filter universe first\n",
    "        universe_df = data_df[\n",
    "            (data_df['dlyprc'] > min_price) &\n",
    "            (data_df['dlycap'] > data_df['dlycap'].quantile(market_cap_percentile))\n",
    "        ].copy()\n",
    "        \n",
    "        logger(f\"Starting universe size: {len(universe_df)} stocks\")\n",
    "        \n",
    "        # Store initial filtered universe\n",
    "        if self.store_intermediate:\n",
    "            self.intermediate_dfs['initial_universe'] = universe_df.copy()\n",
    "\n",
    "        # STAGE 1: Quality Factors Ranking with direct manual ranking\n",
    "        logger(\"Stage 1: Ranking on quality factors\")\n",
    "        \n",
    "        # Direct manual ranking for each quality factor\n",
    "        universe_df['cash_flow_to_asset_rank'] = universe_df['cash_flow_to_asset'].rank(ascending=True)\n",
    "        universe_df['cash_flow_to_liability_rank'] = universe_df['cash_flow_to_liability'].rank(ascending=True)\n",
    "        universe_df['total_asset_turnover_rate_rank'] = universe_df['total_asset_turnover_rate'].rank(ascending=True)\n",
    "        \n",
    "        # Calculate point1 as sum of all quality factor ranks\n",
    "        universe_df['point1'] = universe_df['cash_flow_to_asset_rank'] + universe_df['cash_flow_to_liability_rank'] + universe_df['total_asset_turnover_rate_rank']\n",
    "        \n",
    "        # Sort and keep top 2/3\n",
    "        universe_df.sort_values(by='point1', ascending=False, inplace=True)\n",
    "        universe_df = universe_df.iloc[:len(universe_df)//3*2]\n",
    "        \n",
    "        logger(f\"After quality filter: {len(universe_df)} stocks\")\n",
    "\n",
    "        # Store post-quality filter universe\n",
    "        if self.store_intermediate:\n",
    "            self.intermediate_dfs['post_quality_filter'] = universe_df.copy()\n",
    "        \n",
    "        # Early exit if no stocks remain\n",
    "        if len(universe_df) == 0:\n",
    "            logger(\"No stocks remain after Stage 1 filtering\")\n",
    "            return {}\n",
    "        \n",
    "        # STAGE 2: Growth Factors Ranking with direct manual ranking\n",
    "        logger(\"Stage 2: Ranking on growth factors\")\n",
    "        \n",
    "        # Direct manual ranking for each growth factor\n",
    "        universe_df['gpoa_4q_growth_rank'] = universe_df['gpoa_4q_growth'].rank(ascending=True)\n",
    "        universe_df['roe_rank'] = universe_df['roe'].rank(ascending=True)\n",
    "        universe_df['roic_rank'] = universe_df['roic'].rank(ascending=True)\n",
    "        \n",
    "        # Calculate point3 as sum of all growth factor ranks\n",
    "        universe_df['point3'] = universe_df['gpoa_4q_growth_rank'] + universe_df['roe_rank'] + universe_df['roic_rank']\n",
    "        \n",
    "        # Sort and keep top 1/4\n",
    "        universe_df.sort_values(by='point3', ascending=False, inplace=True)\n",
    "        universe_df = universe_df.iloc[:len(universe_df)//4]\n",
    "        \n",
    "        logger(f\"After growth filter: {len(universe_df)} stocks\")\n",
    "        \n",
    "        # Store post-growth filter universe\n",
    "        if self.store_intermediate:\n",
    "            self.intermediate_dfs['post_growth_filter'] = universe_df.copy()\n",
    "            \n",
    "        # Early exit if no stocks remain\n",
    "        if len(universe_df) == 0:\n",
    "            logger(\"No stocks remain after Stage 2 filtering\")\n",
    "            return {}\n",
    "        \n",
    "        # Early exit if no stocks remain\n",
    "        if len(universe_df) == 0:\n",
    "            logger(\"No stocks remain after Stage 2 filtering\")\n",
    "            return {}\n",
    "        \n",
    "        # STAGE 3: Value and Momentum Factors - Direct rank definitions\n",
    "        logger(\"Stage 3: Using value and momentum factors\")\n",
    "        \n",
    "        # Add rank columns with direct definitions (no loops)\n",
    "        universe_df['earnings_to_price_rank'] = universe_df['earnings_to_price'].rank(ascending=True)\n",
    "        universe_df['cum_return_252d_offset_21d_rank'] = universe_df['cum_return_252d_offset_21d'].rank(ascending=True)\n",
    "        universe_df['cum_return_126d_offset_21d_rank'] = universe_df['cum_return_126d_offset_21d'].rank(ascending=True)\n",
    "        #universe_df['cum_return_21d_rank'] = universe_df['cum_return_21d'].rank(ascending=False)\n",
    "        \n",
    "        # Sum up all rank columns to get point8\n",
    "        universe_df['point8'] = universe_df['earnings_to_price_rank'] + universe_df['cum_return_252d_offset_21d_rank'] + universe_df['cum_return_126d_offset_21d_rank'] #+ universe_df['cum_return_21d_rank']\n",
    "        \n",
    "        # Sort by point8 (higher is better)\n",
    "        universe_df.sort_values(by='point3', ascending=False, inplace=True)\n",
    "        \n",
    "        logger(f\"After stage 3 filtering: ready for final selection\")\n",
    "        \n",
    "        # Store final ranked universe\n",
    "        if self.store_intermediate:\n",
    "            self.intermediate_dfs['final_ranked'] = universe_df.copy()\n",
    "        \n",
    "        # Select final stocks (top N stocks)\n",
    "        selected_stocks = universe_df.head(stock_num).index\n",
    "        \n",
    "        # Store final selected universe\n",
    "        if self.store_intermediate:\n",
    "            self.intermediate_dfs['final_selection'] = universe_df.head(stock_num).copy()\n",
    "        \n",
    "        # Equal weight portfolio\n",
    "        weight = 1.0 / len(selected_stocks) if len(selected_stocks) > 0 else 0\n",
    "        target_portfolio = {int(stock): weight for stock in selected_stocks}\n",
    "        \n",
    "        self.save_intermediate_dataframes(date)\n",
    "        # Log portfolio construction details\n",
    "        logger(f\"Final portfolio: {len(target_portfolio)} stocks selected\")\n",
    "        return target_portfolio\n",
    "    \n",
    "    def get_intermediate_dataframes(self):\n",
    "        \"\"\"\n",
    "        Return the stored intermediate DataFrames\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        dict : {stage_name: dataframe}\n",
    "        \"\"\"\n",
    "        if not self.store_intermediate:\n",
    "            return {\"error\": \"Intermediate DataFrame storage is not enabled. Initialize with store_intermediate=True\"}\n",
    "        return self.intermediate_dfs\n",
    "        \n",
    "    def save_intermediate_dataframes(self, date, directory=\"intermediate_dfs\"):\n",
    "        \"\"\"\n",
    "        Save all intermediate DataFrames to CSV files\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        date : str\n",
    "            Date string for file naming\n",
    "        directory : str\n",
    "            Directory to save files in\n",
    "        \"\"\"\n",
    "        import os\n",
    "        if not self.store_intermediate:\n",
    "            print(\"Intermediate DataFrame storage is not enabled. Initialize with store_intermediate=True\")\n",
    "            return\n",
    "            \n",
    "        # Create directory if it doesn't exist\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "        date_str = date.strftime('%Y%m%d')\n",
    "        # Save each DataFrame\n",
    "        for stage, df in self.intermediate_dfs.items():\n",
    "            filename = f\"{directory}/{date_str}_{stage}.csv\"\n",
    "            df.to_csv(filename)\n",
    "        \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all our factors together (no need to separate them)\n",
    "all_factors = [\n",
    "    # Quality factors\n",
    "    'cash_flow_to_asset',\n",
    "    'cash_flow_to_liability',\n",
    "    \n",
    "    'total_asset_turnover_rate',\n",
    "    \n",
    "    \n",
    "    # Growth factors\n",
    "    'gpoa_4q_growth',\n",
    "    'roe',\n",
    "    'roic',\n",
    "    'gpoa_20q_growth',\n",
    "    \n",
    "    # Value factors\n",
    "    'earnings_to_price',\n",
    "    'cum_return_252d_offset_21d',\n",
    "    'cum_return_126d_offset_21d',\n",
    "    'cum_return_21d'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import base strategy classes from strategies.py\n",
    "from strategies import PortfolioStrategy, MultiFactorStrategy1\n",
    "\n",
    "# Create strategy instance\n",
    "strategy = MultiFactorStrategy1(\n",
    "    industry_limit=2,  # Optional: limit 2 stocks per industry\n",
    "    store_intermediate=False  # Store intermediate results\n",
    ")\n",
    "\n",
    "# Get the list of factors required by this strategy\n",
    "all_factors = strategy.get_factor_list()\n",
    "print(f\"Strategy requires these factors: {all_factors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis parameters\n",
    "ANALYSIS_PARAMS = {\n",
    "    'start_date': '2010-01-05',\n",
    "    'end_date': '2023-12-30',\n",
    "    'factor_name': ['gpoa_4q_growth','roe','roic'],\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dates: 100%|██████████| 3522/3522 [04:57<00:00, 11.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data_df_dic, trading_dates = create_extended_analysis_data(\n",
    "    ANALYSIS_PARAMS['start_date'],\n",
    "    ANALYSIS_PARAMS['end_date'],\n",
    "    all_factors,\n",
    "    #ANALYSIS_PARAMS['factor_name'],\n",
    "    'wrds_data.db',\n",
    "    'factor_data'\n",
    ")\n",
    "\n",
    "# Load distribution data\n",
    "distribution_data = load_distribution_data(\n",
    "    ANALYSIS_PARAMS['start_date'],\n",
    "    ANALYSIS_PARAMS['end_date']\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our strategy - just use all factors together with industry diversification\n",
    "strategy = MultiFactorStrategy(\n",
    "    \n",
    "    industry_limit=2  # Optional: limit 2 stocks per industry\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "commission_model = BrokersModel()\n",
    "slippagemodel = FixedSlippageModel(0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting backtest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3521/3521 [06:04<00:00,  9.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and run backtest\n",
    "backtest = Backtest(\n",
    "    cash=10000000,  # Initial cash\n",
    "    commission_model=commission_model,\n",
    "    slippage_model= slippagemodel,\n",
    "    data_df_dic=data_df_dic,\n",
    "    trading_dates=trading_dates,\n",
    "    distribution_data=distribution_data,\n",
    "    factor_list=all_factors, \n",
    "    #factor_list=ANALYSIS_PARAMS['factor_name'],\n",
    "    dir_='backtest_results',\n",
    "    save_format='html',\n",
    "    stock_num=50,\n",
    "    margin_rate=0.06,\n",
    "    rebalance_freq='1w',\n",
    "    rebalance_day=4,\n",
    "    min_price=2.0,\n",
    "    market_cap_percentile=0.5,\n",
    "    #buy_and_hold_list=buy_and_hold,\n",
    "    weight_change_threshold=0.01,\n",
    "    strategy=strategy \n",
    ")\n",
    "\n",
    "# No need for additional parameter setting\n",
    "backtest.backtest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest.plot_performance_summary(interactive=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF files have been saved to backtest_results/:\n",
      "├── 1_metrics_table.pdf\n",
      "├── 2_cumulative_returns.pdf\n",
      "├── 3_drawdown_analysis.pdf\n",
      "└── 4_turnover_analysis.pdf\n"
     ]
    }
   ],
   "source": [
    "backtest.save_performance_summary_pdfs(output_dir='backtest_results',\n",
    "    dpi=2400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example buy and hold portfolio\n",
    "'''\n",
    "buy_and_hold_test_C2 = {\n",
    "    14593: 0.4,\n",
    "    16437: 0.2,\n",
    "    14450: 0.2,\n",
    "    89349: 0.2,\n",
    "#2020-06-01-2020-08-31\n",
    "}\n",
    "buy_and_hold_test_CS = {\n",
    "    14593: 0.4,\n",
    "    80711: 0.2,\n",
    "    75152: 0.1,\n",
    "    15950: 0.1, \n",
    "    14252: 0.1,\n",
    "    25129: 0.1\n",
    "#2020-11-01-2020-12-31\n",
    "}\n",
    "buy_and_hold_test_M2MU = {\n",
    "    14593: 0.1,\n",
    "    18790:0.1,\n",
    "    89942:0.1,\n",
    "    16836:0.1,\n",
    "    89901:0.1,\n",
    "    17016:0.1,\n",
    "    92910:0.1,\n",
    "    10065:0.1,\n",
    "    15282:0.1,\n",
    "    91278:0.1\n",
    "#2020-09-01-2020-12-31\n",
    "}\n",
    "buy_and_hold_test_O1P1 = {\n",
    "    14593: 0.5,\n",
    "    49680:0.1,\n",
    "    26825:0.1,\n",
    "    88233:0.1,\n",
    "    17250:0.1,\n",
    "    88901:0.1\n",
    "#2023-09-01-2023-11-30\n",
    "}\n",
    "buy_and_hold_D1D2 = {\n",
    "    14593: 0.4,\n",
    "    12413:0.1,\n",
    "    13191:0.1,\n",
    "    81560:0.1,\n",
    "    90499:0.1,\n",
    "    20807:0.1,\n",
    "    14433:0.1\n",
    "#2022-03-01-2022-04-30\n",
    "}\n",
    "buy_and_hold_suspended = {\n",
    "    14593: 0.4,\n",
    "    20740: 0.2,\n",
    "    21847: 0.2,\n",
    "    14127: 0.2\n",
    "#2021-11-01-2023-04-30\n",
    "}\n",
    "buy_and_hold = {\n",
    "    14593: 0.4,\n",
    "    20740: 0.2,\n",
    "    21847: 0.2,\n",
    "    14127: 0.2,\n",
    "    16437: 0.2,\n",
    "    14450: 0.2,\n",
    "    89349: 0.2,\n",
    "    12413:0.1,\n",
    "    13191:0.1,\n",
    "    81560:0.1,\n",
    "    90499:0.1,\n",
    "    20807:0.1,\n",
    "    14433:0.1,\n",
    "    49680:0.1,\n",
    "    26825:0.1,\n",
    "    88233:0.1,\n",
    "    17250:0.1,\n",
    "    88901:0.1,\n",
    "    18790:0.1,\n",
    "    89942:0.1,\n",
    "    16836:0.1,\n",
    "    89901:0.1,\n",
    "    17016:0.1,\n",
    "    92910:0.1,\n",
    "    10065:0.1,\n",
    "    15282:0.1,\n",
    "    91278:0.1,\n",
    "    80711: 0.2,\n",
    "    75152: 0.1,\n",
    "    15950: 0.1, \n",
    "    14252: 0.1,\n",
    "    25129: 0.1,\n",
    "#2021-11-01-2023-04-30\n",
    "}\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
