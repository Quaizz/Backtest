{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting duckdb\n",
      "  Downloading duckdb-1.1.3-cp311-cp311-win_amd64.whl.metadata (781 bytes)\n",
      "Downloading duckdb-1.1.3-cp311-cp311-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.9/11.0 MB 29.1 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.6/11.0 MB 33.3 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 4.1/11.0 MB 32.8 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.9/11.0 MB 34.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.6/11.0 MB 34.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.4/11.0 MB 35.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.9/11.0 MB 36.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 34.6 MB/s eta 0:00:00\n",
      "Installing collected packages: duckdb\n",
      "Successfully installed duckdb-1.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install duckdb --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wrds\n",
    "import duckdb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRDS recommends setting up a .pgpass file.\n",
      "Created .pgpass file successfully.\n",
      "You can create this file yourself at any time with the create_pgpass_file() function.\n",
      "Loading library list...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "db = wrds.Connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximately 607568 rows in compsamp_snapshot.wrds_csq_pit.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nullable</th>\n",
       "      <th>type</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pitdate1</td>\n",
       "      <td>True</td>\n",
       "      <td>DATE</td>\n",
       "      <td>Point-in-Time Effective Date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pitdate2</td>\n",
       "      <td>True</td>\n",
       "      <td>DATE</td>\n",
       "      <td>Point-in-Time Observation End Date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gvkey</td>\n",
       "      <td>True</td>\n",
       "      <td>VARCHAR(6)</td>\n",
       "      <td>Global Company Key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indfmt</td>\n",
       "      <td>True</td>\n",
       "      <td>VARCHAR(12)</td>\n",
       "      <td>Industry Format</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>consol</td>\n",
       "      <td>True</td>\n",
       "      <td>VARCHAR(2)</td>\n",
       "      <td>Level of Consolidation - Company Interim Descr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>xopty</td>\n",
       "      <td>True</td>\n",
       "      <td>DOUBLE PRECISION</td>\n",
       "      <td>Implied Option Expense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>xrdq</td>\n",
       "      <td>True</td>\n",
       "      <td>DOUBLE PRECISION</td>\n",
       "      <td>Research and Development Expense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>xrdy</td>\n",
       "      <td>True</td>\n",
       "      <td>DOUBLE PRECISION</td>\n",
       "      <td>Research and Development Expense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>xsgaq</td>\n",
       "      <td>True</td>\n",
       "      <td>DOUBLE PRECISION</td>\n",
       "      <td>Selling, General and Administrative Expenses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>xsgay</td>\n",
       "      <td>True</td>\n",
       "      <td>DOUBLE PRECISION</td>\n",
       "      <td>Selling, General and Administrative Expenses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>620 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         name  nullable              type  \\\n",
       "0    pitdate1      True              DATE   \n",
       "1    pitdate2      True              DATE   \n",
       "2       gvkey      True        VARCHAR(6)   \n",
       "3      indfmt      True       VARCHAR(12)   \n",
       "4      consol      True        VARCHAR(2)   \n",
       "..        ...       ...               ...   \n",
       "615     xopty      True  DOUBLE PRECISION   \n",
       "616      xrdq      True  DOUBLE PRECISION   \n",
       "617      xrdy      True  DOUBLE PRECISION   \n",
       "618     xsgaq      True  DOUBLE PRECISION   \n",
       "619     xsgay      True  DOUBLE PRECISION   \n",
       "\n",
       "                                               comment  \n",
       "0                         Point-in-Time Effective Date  \n",
       "1                   Point-in-Time Observation End Date  \n",
       "2                                   Global Company Key  \n",
       "3                                      Industry Format  \n",
       "4    Level of Consolidation - Company Interim Descr...  \n",
       "..                                                 ...  \n",
       "615                             Implied Option Expense  \n",
       "616                   Research and Development Expense  \n",
       "617                   Research and Development Expense  \n",
       "618       Selling, General and Administrative Expenses  \n",
       "619       Selling, General and Administrative Expenses  \n",
       "\n",
       "[620 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.describe_table(library=\"compsamp_snapshot\", table=\"wrds_csq_pit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximately 9981955 rows in comp_snapshot.wrds_csq_pit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                DATE\n",
       "1                DATE\n",
       "2          VARCHAR(6)\n",
       "3         VARCHAR(12)\n",
       "4          VARCHAR(2)\n",
       "            ...      \n",
       "667    NUMERIC(19, 4)\n",
       "668    NUMERIC(19, 4)\n",
       "669    NUMERIC(19, 4)\n",
       "670    NUMERIC(19, 4)\n",
       "671    NUMERIC(19, 4)\n",
       "Name: type, Length: 672, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.describe_table(library=\"comp_snapshot\", table=\"wrds_csq_pit\")['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximately 607568 rows in compsamp_snapshot.wrds_csq_pit.\n",
      "0                 DATE\n",
      "2           VARCHAR(6)\n",
      "3          VARCHAR(12)\n",
      "4           VARCHAR(2)\n",
      "5           VARCHAR(1)\n",
      "6             SMALLINT\n",
      "8     DOUBLE PRECISION\n",
      "10          VARCHAR(3)\n",
      "11             INTEGER\n",
      "Name: type, dtype: object\n"
     ]
    }
   ],
   "source": [
    "unique_types = db.describe_table(library=\"compsamp_snapshot\", table=\"wrds_csq_pit\")['type'].astype(str).drop_duplicates()\n",
    "\n",
    "print(unique_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximately 607568 rows in compsamp_snapshot.wrds_csq_pit.\n",
      "Processed 100000 rows\n",
      "Processed 200000 rows\n",
      "Processed 300000 rows\n",
      "Processed 400000 rows\n",
      "Processed 500000 rows\n",
      "Processed 600000 rows\n",
      "Processed 700000 rows\n"
     ]
    }
   ],
   "source": [
    "# Create DuckDB connection'''\n",
    "'''\n",
    "duck_conn = duckdb.connect('wrds_data.db')\n",
    "\n",
    "\n",
    "# Get schema information\n",
    "schema_info = db.describe_table(library=\"compsamp_snapshot\", table=\"wrds_csq_pit\")\n",
    "\n",
    "# Drop existing table if it exists\n",
    "duck_conn.execute(\"DROP TABLE IF EXISTS wrds_csq_pit\")\n",
    "\n",
    "# Create table with exact schema mapping\n",
    "create_table_sql = \"CREATE TABLE wrds_csq_pit (\"\n",
    "columns = []\n",
    "for _, row in schema_info.iterrows():\n",
    "    col_name = row['name']\n",
    "    wrds_type = str(row['type']).upper()\n",
    "    \n",
    "    if wrds_type == 'DATE':\n",
    "        duck_type = 'DATE'\n",
    "    elif wrds_type.startswith('VARCHAR'):\n",
    "        duck_type = wrds_type\n",
    "    elif wrds_type == 'SMALLINT':\n",
    "        duck_type = 'SMALLINT'\n",
    "    elif wrds_type == 'INTEGER':\n",
    "        duck_type = 'INTEGER'\n",
    "    elif 'DOUBLE PRECISION' in wrds_type:\n",
    "        duck_type = 'DOUBLE'\n",
    "    else:\n",
    "        duck_type = 'VARCHAR'\n",
    "        \n",
    "    columns.append(f\"{col_name} {duck_type}\")\n",
    "\n",
    "create_table_sql += \", \".join(columns) + \")\"\n",
    "duck_conn.execute(create_table_sql)\n",
    "\n",
    "# Process in chunks\n",
    "chunksize = 100000\n",
    "offset = 0\n",
    "\n",
    "while True:\n",
    "    query = f\"\"\"\n",
    "        select * \n",
    "        from compsamp_snapshot.wrds_csq_pit \n",
    "        LIMIT {chunksize} \n",
    "        OFFSET {offset}\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        chunk = db.raw_sql(query)\n",
    "        \n",
    "        if len(chunk) == 0:\n",
    "            break\n",
    "        \n",
    "        # Handle date columns properly\n",
    "        date_cols = schema_info[schema_info['type'].astype(str).str.upper() == 'DATE']['name'].tolist()\n",
    "        for col in date_cols:\n",
    "            if col in chunk.columns:\n",
    "                # Convert dates to strings, handling special cases\n",
    "                def convert_date(x):\n",
    "                    if pd.isna(x):\n",
    "                        return None\n",
    "                    elif str(x) == '9999-12-31':\n",
    "                        return 'infinity'\n",
    "                    try:\n",
    "                        return pd.to_datetime(x).strftime('%Y-%m-%d')\n",
    "                    except:\n",
    "                        return None\n",
    "                \n",
    "                chunk[col] = chunk[col].apply(convert_date)\n",
    "        \n",
    "        # Insert the chunk into DuckDB\n",
    "        duck_conn.register('temp_chunk', chunk)\n",
    "        duck_conn.sql('INSERT INTO wrds_csq_pit SELECT * FROM temp_chunk')\n",
    "        \n",
    "        offset += chunksize\n",
    "        print(f\"Processed {offset} rows\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error at offset {offset}: {str(e)}\")\n",
    "        raise\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximately 9981955 rows in comp_snapshot.wrds_csq_pit.\n",
      "Total rows to process: 9981955\n",
      "Processed 500000 rows out of 9981955 (5.01%)\n",
      "Processed 1000000 rows out of 9981955 (10.02%)\n",
      "Processed 1500000 rows out of 9981955 (15.03%)\n",
      "Processed 2000000 rows out of 9981955 (20.04%)\n",
      "Processed 2500000 rows out of 9981955 (25.05%)\n",
      "Processed 3000000 rows out of 9981955 (30.05%)\n",
      "Processed 3500000 rows out of 9981955 (35.06%)\n",
      "Processed 4000000 rows out of 9981955 (40.07%)\n",
      "Processed 4500000 rows out of 9981955 (45.08%)\n",
      "Processed 5000000 rows out of 9981955 (50.09%)\n",
      "Processed 5500000 rows out of 9981955 (55.10%)\n",
      "Processed 6000000 rows out of 9981955 (60.11%)\n",
      "Processed 6500000 rows out of 9981955 (65.12%)\n",
      "Processed 7000000 rows out of 9981955 (70.13%)\n",
      "Processed 7500000 rows out of 9981955 (75.14%)\n",
      "Processed 8000000 rows out of 9981955 (80.14%)\n",
      "Processed 8500000 rows out of 9981955 (85.15%)\n",
      "Processed 9000000 rows out of 9981955 (90.16%)\n",
      "Processed 9500000 rows out of 9981955 (95.17%)\n",
      "Processed 9981955 rows out of 9981955 (100.00%)\n"
     ]
    }
   ],
   "source": [
    "# Create DuckDB connection\n",
    "duck_conn = duckdb.connect('wrds_data.db')\n",
    "\n",
    "\n",
    "\n",
    "# Get schema information \n",
    "schema_info = db.describe_table(library=\"comp_snapshot\", table=\"wrds_csq_pit\")\n",
    "\n",
    "# Get total row count first\n",
    "total_rows = db.raw_sql(\"SELECT COUNT(*) FROM comp_snapshot.wrds_csq_pit\").iloc[0,0]\n",
    "print(f\"Total rows to process: {total_rows}\")\n",
    "\n",
    "# Drop existing table if it exists\n",
    "duck_conn.execute(\"DROP TABLE IF EXISTS wrds_csq_pit\")\n",
    "\n",
    "# Create table with exact schema mapping\n",
    "create_table_sql = \"CREATE TABLE wrds_csq_pit (\"\n",
    "columns = []\n",
    "for _, row in schema_info.iterrows():\n",
    "   col_name = row['name']\n",
    "   wrds_type = str(row['type']).upper()\n",
    "   \n",
    "   if wrds_type == 'DATE':\n",
    "       duck_type = 'DATE'\n",
    "   elif wrds_type.startswith('VARCHAR'):\n",
    "       duck_type = wrds_type\n",
    "   elif wrds_type == 'SMALLINT':\n",
    "       duck_type = 'SMALLINT'\n",
    "   elif wrds_type == 'INTEGER':\n",
    "       duck_type = 'INTEGER'\n",
    "   elif 'DOUBLE PRECISION' in wrds_type:\n",
    "       duck_type = 'DOUBLE'\n",
    "   else:\n",
    "       duck_type = 'VARCHAR'\n",
    "       \n",
    "   columns.append(f\"{col_name} {duck_type}\")\n",
    "\n",
    "create_table_sql += \", \".join(columns) + \")\"\n",
    "duck_conn.execute(create_table_sql)\n",
    "\n",
    "# Process in chunks\n",
    "chunksize = 500000\n",
    "offset = 0\n",
    "\n",
    "while True:\n",
    "   query = f\"\"\"\n",
    "       select * \n",
    "       from comp_snapshot.wrds_csq_pit \n",
    "       LIMIT {chunksize} \n",
    "       OFFSET {offset}\n",
    "   \"\"\"\n",
    "   \n",
    "   try:\n",
    "       chunk = db.raw_sql(query)\n",
    "       \n",
    "       if len(chunk) == 0:\n",
    "           break\n",
    "       \n",
    "       # Handle date columns properly\n",
    "       date_cols = schema_info[schema_info['type'].astype(str).str.upper() == 'DATE']['name'].tolist()\n",
    "       for col in date_cols:\n",
    "           if col in chunk.columns:\n",
    "               # Convert dates to strings, handling special cases\n",
    "               def convert_date(x):\n",
    "                   if pd.isna(x):\n",
    "                       return None\n",
    "                   elif str(x) == '9999-12-31':\n",
    "                       return '2200-01-01'  # New upper bound\n",
    "                   try:\n",
    "                       return pd.to_datetime(x).strftime('%Y-%m-%d')\n",
    "                   except:\n",
    "                       return None\n",
    "               \n",
    "               chunk[col] = chunk[col].apply(convert_date)\n",
    "       \n",
    "       # Insert the chunk into DuckDB\n",
    "       duck_conn.register('temp_chunk', chunk)\n",
    "       duck_conn.sql('INSERT INTO wrds_csq_pit SELECT * FROM temp_chunk')\n",
    "       \n",
    "       offset += chunksize\n",
    "       print(f\"Processed {min(offset, total_rows)} rows out of {total_rows} ({(min(offset, total_rows)/total_rows*100):.2f}%)\")\n",
    "       \n",
    "   except Exception as e:\n",
    "       print(f\"Error at offset {offset}: {str(e)}\")\n",
    "       raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 9981955\n",
      "Total Columns: 672\n"
     ]
    }
   ],
   "source": [
    "# Count rows\n",
    "total_rows = duck_conn.execute(\"SELECT COUNT(*) AS total_rows FROM wrds_csq_pit\").fetchdf()\n",
    "\n",
    "# Count columns\n",
    "total_columns = duck_conn.execute(\"\"\"\n",
    "    SELECT COUNT(*) AS total_columns\n",
    "    FROM information_schema.columns\n",
    "    WHERE table_name = 'wrds_csq_pit'\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "# Combine results\n",
    "print(f\"Total Rows: {total_rows['total_rows'][0]}\")\n",
    "print(f\"Total Columns: {total_columns['total_columns'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "duck_conn.close()\n",
    "db.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
